# default port, service name.
druid.service=druid/prod/middlemanager
druid.port=8091

# HTTP server threads
druid.server.http.numThreads=50

# Processing threads and buffers
druid.processing.buffer.sizeBytes=268435456
druid.processing.numThreads=4

# Hadoop indexing
druid.indexer.task.hadoopWorkingPath=/druid/indexing-tmp
druid.indexer.task.defaultHadoopCoordinates=["org.apache.hadoop:hadoop-client:3.1.1.3.1.4.0-315"]

# Task launch parameters
#  memory = druid.processing.buffer.sizeBytes[268,435,456] * ( druid.processing.numThreads[4] + 1 )
druid.indexer.runner.javaOpts=-server -Xmx3584m  -XX:+UseG1GC -XX:MaxGCPauseMillis=100 -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -Dhdp.version=3.1.4.0-315 -Duser.timezone=UTC -Dfile.encoding=UTF-8 -Djava.util.logging.manager=org.apache.logging.log4j.jul.LogManager
druid.indexer.task.baseTaskDir=/data/opt/druid/var/task

# Peon properties
druid.indexer.fork.property.druid.monitoring.monitors=["io.druid.java.util.metrics.JvmMonitor"]
druid.indexer.fork.property.druid.processing.buffer.sizeBytes=268435456
druid.indexer.fork.property.druid.processing.numThreads=4
druid.indexer.fork.property.druid.segmentCache.locations=[{"path": "/data/opt/druid/segment-cache", "maxSize": 0}]
druid.indexer.fork.property.druid.server.http.numThreads=10

druid.worker.capacity=8
druid.worker.ip=localhost
druid.worker.version=0
hdp.version=3.1.4.0-315
